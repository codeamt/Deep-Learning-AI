<h1 align="center">Neural Machine Translation with Attention</h1> 

<p align="center">
<img src="https://ucarecdn.com/84337d63-f2aa-4f91-b5db-de1d67164f27/" width="70%" height="60%" >
</p>

<b>Goal:</b> Using an attention model, build a Neural Machine Translation (NMT) model to translate human readable dates (e.g., "25th of June, 2009") into machine readable dates (e.g., "2009-06-25").

<b>Andrew Ng's Learning Objectives:</b> 

- [x] Understand how to implement the attention mechanism/many-to-many model presented in the lecture videos to learn complex mappings from one sequence to another.
- [x] See how BRNN layers work in practice  

<b>Special thanks to NVIDIA for partnering on this state of the art assignment!</b>

[View Jupyter Notebook](https://github.com/codeamt/Deep-Learning-AI/blob/master/5%20Sequence%20Models/Implementations/3%20Sequence%20Models%20and%20Attention%20Mechanism%20/1-PA/Neural%2Bmachine%2Btranslation%2Bwith%2Battention%2B-%2Bv4.ipynb)
