<h1 align="center">DLAI-1: Neural Network and Deep Learning</h1>


<p align="center">
<img src="https://ucarecdn.com/cf7d2668-ef01-489f-a591-c8f6b4274c2d/" width="70%" height="60%">
</p>

<h1 align="center">About the Course</h1>

In the first course of deeplearning.ai, Andrew Ng provides a thoughtful introduction to the foundational concepts of deep learning. 

Deep learning, a subsect of Machine Learning, denotes the regressive process of learning the appropriate co-efficients ("the weights") and bias values (together, the parameters) for multi-dimensional inputs (meaning, featurized x values - say, a record of houses and respective features, like number of bedrooms, bathrooms, windows, etc., for those houses) and uses these learned variables to architect a schematic formula (a model) that predicts outputs (y values, sometimes also multi-dimensional, but following the example, say the market price) for those inputs with a freakishly high level of accuracy. 

We start off basic in the first week, unpacking how logistic regression, gradient descent and cost calculation work for a single training example (e.g., a single house-to-price mapping) and move outward to apply these processes for some (n) number of training examples (e.g., ALL the houses, all in one loop). 

The magic of deep learning happens in the inner parts of an architected model, using layers of what we call "neurons" that activate the learning process. The actual "learning" happens with the help of Calculus and derivatives, when we perform "back propogation" to slowly reduce error of our model's guesses.

Ng goes beyond providing the theory, and demonstrates how to implement this process in actual Python code, including methods for vectorizing n number of inputs to decrease the time complexity of operations and speed up the weight learning process.

## Lessons

- [x] Neural Network Basics
- [x] Shallow Neural Networks
- [x] Deep Neural Networks


<p align="center">
<img src="https://ucarecdn.com/8b064603-8fc5-471b-80d8-4a621d2c665d/" width="60%" height="50%">
</p>


## Programming Assignments

- [x] [Logistic Regression with a Neural Network mindset](https://github.com/codeamt/Deep-Learning-AI/tree/master/1%20Neural%20Networks%20and%20Deep%20Learning/Implementations/2%20Neural%20Networks%20Basics/2-PA)
- [x] [Planar data classification with a hidden layer](https://github.com/codeamt/Deep-Learning-AI/blob/master/1%20Neural%20Networks%20and%20Deep%20Learning/Implementations/3%20Shallow%20Neural%20Networks/1-PA/README.md)
- [x] [Building your deep neural network: step by step](https://github.com/codeamt/Deep-Learning-AI/blob/master/1%20Neural%20Networks%20and%20Deep%20Learning/Implementations/4%20Deep%20Neural%20Networks/1-PA/README.md)
- [x] [Deep Neural Network Application](https://github.com/codeamt/Deep-Learning-AI/blob/master/1%20Neural%20Networks%20and%20Deep%20Learning/Implementations/4%20Deep%20Neural%20Networks/2-PA/README.md)


## Additional Material

Heroes of Deep Learning Interviews:


<p align="center">
 **Geoffrey Hinton**
  <br>
<img src="" width="400px" height="350px">
</p>


<p align="center">
  **Ian Goodfellow**
  <br>
<img src="" width="400px" height="350px">
</p>


<p align="center">
  **Pieter Abbeel**
  <br>
<img src="" width="400px" height="350px">
</p>
